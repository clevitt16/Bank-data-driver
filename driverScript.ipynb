{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"tesseract\")\n",
    "install.packages(\"magick\")\n",
    "install.packages(\"stringr\")\n",
    "install.packages(\"pdftools\")\n",
    "library(magick)\n",
    "library(tesseract)\n",
    "library(stringr)\n",
    "library(pdftools)\n",
    "\n",
    "########################################################################################\n",
    "#  Main driver - extracts data from a multi-page PDF into a dataframe\n",
    "#  main function takes 3 arguments: path to PDF file, the page number of the first\n",
    "#  page in the file, and the name of the county of the first page in the file\n",
    "#  Note: on data loss or other error, program saves extracted data in a csv and\n",
    "#        begins a new csv. Always need to check the end of prev. csv (where the error happened)\n",
    "#        and beginning of new csv (where prev. state, county, and bank data may be incorrect)\n",
    "#        there may also be data from prev. page on new csv!\n",
    "#\n",
    "#  IMPORTANT: ensure that working directory is Bank-data\n",
    "#\n",
    "#  TO RUN:\n",
    "#  source(\"main.R\")\n",
    "#  main(\"test/1993B1_1.pdf\", 1, \"Fairfield\")\n",
    "#\n",
    "########################################################################################\n",
    "\n",
    "# format of final dataframe:  \n",
    "# STATE | COUNTY | BANK | BRANCH | CITY | ZIP | IPC DEPOSITS | ALL OTHER DEPOSITS | TOTAL DEPOSITS\n",
    "\n",
    "#source(\"ColumnCropping/cropColumns.R\")\n",
    "#source(\"dataProcessing.R\")\n",
    "\n",
    "# add a pageNum column to every table! for tracking purposes!\n",
    "\n",
    "main <- function(pdfName, firstPage, firstCounty) {\n",
    "    # read in image, set initial variables, create dataframe\n",
    "    image <- image_read_pdf(pdfName, density = 600)\n",
    "    pageNum <- firstPage\n",
    "    state <- \"\"\n",
    "    county <- firstCounty\n",
    "    bank <- \"\"\n",
    "    finalDF <- data.frame(matrix(ncol = 10, nrow = 0))\n",
    "    colnames(finalDF) <- c(\"PageNum\", \"State\", \"County\", \"Bank\", \"Branch\", \"City\", \"ZIP\", \"IPC Deposits\", \"All Other Deposits\", \"Total Deposits\")\n",
    "    \n",
    "    # create folder to store CSVs\n",
    "    if (dir.exists(\"/home/idies/workspace/Storage/Casey/persistent/output\")){\n",
    "        unlink(\"/home/idies/workspace/Storage/Casey/persistent/output\", recursive = TRUE)\n",
    "    } \n",
    "    dir.create(\"/home/idies/workspace/Storage/Casey/persistent/output\")\n",
    "    \n",
    "    # will iterate through each page, create a clean dataframe for it, and append it to final\n",
    "    for (page in 1:length(image)) {\n",
    "        print(paste0(\"Processing page \", pageNum, \" ------------------------------------------\"))\n",
    "        # note that findCrop will always give you data that is a cont. of current county, or includes new county\n",
    "        cropColumns <- cropColumns(image[page], pageNum)\n",
    "        if (is.null(cropColumns[[1]]) & is.null(cropColumns[[2]])) { # indicates page cropping failed\n",
    "            print(paste0(\"<<< failed to crop page \", pageNum, \", abandoning page and beginning new csv >>>\"))\n",
    "            write.csv(finalDF, paste0(\"/home/idies/workspace/Storage/Casey/persistent/output/pg\", firstPage, \"-\", pageNum - 1, \".csv\"), row.names = FALSE)\n",
    "            firstPage <- pageNum + 1\n",
    "            finalDF <- data.frame(matrix(ncol = 10, nrow = 0))\n",
    "            colnames(finalDF) <- c(\"PageNum\", \"State\", \"County\", \"Bank\", \"Branch\", \"City\", \"ZIP\", \"IPC Deposits\", \"All Other Deposits\", \"Total Deposits\")\n",
    "            pageNum <- pageNum + 1\n",
    "            next\n",
    "        }\n",
    "        state <- cropColumns[[1]]\n",
    "        for (i in 2:length(cropColumns)) { # for each vector of extracted text (corresponding to a horizontal cropped section)\n",
    "            columns <- cropColumns[[i]]\n",
    "            splitColumns <- strsplit(columns, '\\n')         # list of character vectors containing the entries of each column\n",
    "            toAppend <- dataProcessing(splitColumns, county, state, bank)\n",
    "            toAppend <- cbind(data.frame(\"PageNum\" = rep(pageNum, nrow(toAppend))), toAppend)\n",
    "            lastIndex <- nrow(toAppend)\n",
    "            county <- toAppend$County[lastIndex] # reset the county and bank info for next img/page\n",
    "            bank <- toAppend$Bank[lastIndex]\n",
    "            finalDF <- rbind(finalDF, toAppend) # append new data to finalDF\n",
    "            # check for data loss, stop if found\n",
    "            for (col in 1:ncol(toAppend)) {\n",
    "                lastVal <- toAppend[lastIndex, col]\n",
    "                if (!is.na(lastVal) & lastVal == \"#\") {\n",
    "                    write.csv(finalDF, paste0(\"/home/idies/workspace/Storage/Casey/persistent/output/pg\", firstPage, \"-\", pageNum, \".csv\"), row.names = FALSE)\n",
    "                    #stop(paste0(\"probable data loss at page \", pageNum))\n",
    "                    print(paste0(\"<<< probable data loss at page \", pageNum, \", beginning new csv >>>\"))\n",
    "                    firstPage <- pageNum\n",
    "                    if (i == length(cropColumns)) {\n",
    "                        firstPage <- pageNum + 1\n",
    "                    }\n",
    "                    finalDF <- data.frame(matrix(ncol = 10, nrow = 0))\n",
    "                    colnames(finalDF) <- c(\"PageNum\", \"State\", \"County\", \"Bank\", \"Branch\", \"City\", \"ZIP\", \"IPC Deposits\", \"All Other Deposits\", \"Total Deposits\")\n",
    "                    break\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        pageNum <- pageNum + 1\n",
    "    }\n",
    "    \n",
    "    #fileName <- tail(strsplit(pdfName, '/')[[1]], n = 1)\n",
    "    #write.csv(finalDF, paste0(fileName, \"data.csv\"), row.names = FALSE)\n",
    "    if (firstPage < pageNum) {\n",
    "        write.csv(finalDF, paste0(\"/home/idies/workspace/Storage/Casey/persistent/output/pg\", firstPage, \"-\", pageNum - 1, \".csv\"), row.names = FALSE)\n",
    "    }\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "NUM_COLUMNS <- 6\n",
    "FIRST_NUMERIC_COL <- 4\n",
    "LAST_NUMERIC_COL <- 6\n",
    "\n",
    "dataProcessing <- function(splitColumns, origCounty, state, origBank) {\n",
    "    \n",
    "    # delete unneccessary whitespace data\n",
    "    for (i in 1:NUM_COLUMNS) {\n",
    "        col <- splitColumns[[i]]\n",
    "        whiteSpaces <- col == \"\"\n",
    "        splitColumns[[i]] <- splitColumns[[i]][!whiteSpaces]\n",
    "    }\n",
    "    \n",
    "    # 2 cases\n",
    "    #   1) data in splitColumns all belongs to origCounty\n",
    "    #   2) data in splitColumns belongs to a new county that will be at the top of the data\n",
    "    \n",
    "    # check if this data belongs to origCounty or a new county!\n",
    "    county <- origCounty\n",
    "    columnOne <- splitColumns[[1]]\n",
    "    indexParen1 <- grep(\"(\", columnOne, fixed = TRUE)\n",
    "    indexParen2 <- grep(\")\", columnOne, fixed = TRUE)\n",
    "    indexOfCounty <- intersect(indexParen1, indexParen2)\n",
    "    if (length(indexOfCounty) != 0) {\n",
    "        indexOfCounty <- indexOfCounty[1]\n",
    "        theoreticallyNewCountyLine <- strsplit(columnOne[indexOfCounty], \" \")[[1]]\n",
    "        indexOfParenString <- grep(\"(\", theoreticallyNewCountyLine, fixed = TRUE)\n",
    "        if (length(indexOfParenString) > 1) {\n",
    "            theoreticallyNewCountyLine <- theoreticallyNewCountyLine[-indexOfParenString[1]]\n",
    "            indexOfParenString <- indexOfParenString[-2]\n",
    "        }\n",
    "        parenString <- theoreticallyNewCountyLine[indexOfParenString] # edge case: tesseract reads County (003 )\n",
    "        if (grep(\")\", theoreticallyNewCountyLine, fixed = TRUE) == indexOfParenString + 1){\n",
    "            parenString <- paste0(parenString, theoreticallyNewCountyLine[indexOfParenString + 1])\n",
    "        }\n",
    "        if (str_length(parenString) == 5) {\n",
    "            # print(paste0(\"length should be 5, deleting: \", parenString))\n",
    "            tokens <- indexOfParenString:length(theoreticallyNewCountyLine)\n",
    "            county <- paste(theoreticallyNewCountyLine[-tokens], collapse = \" \") # possibly need to join for multi-word counties?\n",
    "            deleteRows <- c(rep(TRUE, length(columnOne)))\n",
    "            deleteRows[indexOfCounty] <- FALSE\n",
    "            deleteRows[indexOfCounty + 1] <- FALSE # indexOfCounty can be a vector, so this deletes all!\n",
    "            deleteRows[indexOfCounty - 1] <- FALSE\n",
    "            splitColumns[[1]] <- columnOne[deleteRows]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # all column data vectors need to have same length before putting in dataframe\n",
    "    greatestLength <- 0\n",
    "    for (i in 1:NUM_COLUMNS) {        # identify the column with the greatest length\n",
    "        len <- length(splitColumns[[i]])\n",
    "        if (len > greatestLength) {\n",
    "            greatestLength <- len\n",
    "        }\n",
    "    }\n",
    "    stringData <- data.frame(Temp = 1:greatestLength)  # dataframe shell\n",
    "    for (i in 1:NUM_COLUMNS) {\n",
    "        col = splitColumns[[i]]\n",
    "        if (length(col) < greatestLength) {\n",
    "            col <- c(col, rep('#', greatestLength - length(col))) # add '#' characters to fill in any short columns\n",
    "        }\n",
    "        stringData[paste0(\"Col\", i)] <- col\n",
    "    }\n",
    "    stringData <- stringData[-1]\n",
    "\n",
    "    \n",
    "    # clean data - remove all periods/commas, replace all lone 'o' or 'O' with '0'\n",
    "    stringData <- cleanData(stringData, FIRST_NUMERIC_COL, LAST_NUMERIC_COL)\n",
    "    \n",
    "\n",
    "    # separating bank and branch names into different columns - deletion part deactivated\n",
    "    stringData <- separateBanksAndBranches(stringData, origBank)\n",
    "    \n",
    "    # add and fill county column\n",
    "    stringData <- cbind(data.frame(\"County\" = rep(county, nrow(stringData))), stringData)\n",
    "    \n",
    "    # add and fill state column\n",
    "    stringData <- cbind(data.frame(\"State\" = rep(state, nrow(stringData))), stringData)\n",
    "\n",
    "    colnames(stringData) <- c(\"State\", \"County\", \"Bank\", \"Branch\", \"City\", \"ZIP\", \"IPC Deposits\", \"All Other Deposits\", \"Total Deposits\")\n",
    "    \n",
    "    return(stringData)\n",
    "}\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Given the first column as a character vector, searches for the start of a new county\n",
    "# Returns a list containing:\n",
    "#   vector of indexes of county change (or -1 if no new county)\n",
    "#   vector of strings containing the name of the new counties\n",
    "findCounty <- function(columnOne) {\n",
    "    counties <- vector(mode = \"character\")\n",
    "    index <- -1\n",
    "    indexParen1 <- grep(\"(\", columnOne, fixed = TRUE)\n",
    "    indexParen2 <- grep(\")\", columnOne, fixed = TRUE)\n",
    "    indexOfCounties <- intersect(indexParen1, indexParen2)\n",
    "    if (length(indexOfCounties) != 0) {\n",
    "        index <- indexOfCounties\n",
    "        split <- strsplit(columnOne[indexOfCounties], \" \")\n",
    "        for (i in 1:length(indexOfCounties)) {\n",
    "            counties <- c(counties, split[[i]][1])\n",
    "        }\n",
    "    }\n",
    "    r <- list(index, counties)\n",
    "    return(r)\n",
    "}\n",
    "\n",
    "# Given the first column as a character vector, searches for the totals table indicating the end of a county\n",
    "# Returns index of first row in the table (or -1 if no county change)\n",
    "findCountyTotals <- function(columnOne) {\n",
    "    index <- -1\n",
    "    indexOfTotals <- grep(\"COUNTY TOTALS\", columnOne, fixed = TRUE)\n",
    "    if (length(indexOfTotals) != 0) {\n",
    "        index <- indexOfTotals\n",
    "    }\n",
    "    return(index)\n",
    "}\n",
    "\n",
    "# Cleans the numeric columns of dataframe of extracted text data and returns it\n",
    "# Specifically, it deletes periods and commas and changes all lone 'o' and 'O's to '0's\n",
    "cleanData <- function(dirtyDF, firstNumericCol, lastNumericCol) {\n",
    "    for (i in 1:ncol(dirtyDF)) {\n",
    "        dirtyDF[i] <- str_replace_all(dirtyDF[[i]], '[.]', ',')\n",
    "        dirtyDF[i] <- str_replace_all(dirtyDF[[i]], '[,]', '')\n",
    "        if (i >= firstNumericCol & i <= lastNumericCol) {\n",
    "            dirtyDF[i] <- str_replace_all(dirtyDF[[i]], '[o]', '0')\n",
    "            dirtyDF[i] <- str_replace_all(dirtyDF[[i]], '[O]', '0')\n",
    "        }\n",
    "    }\n",
    "    return(dirtyDF)\n",
    "}\n",
    "\n",
    "# Given the dataframe of text data, separates banks and branch names into separate columns\n",
    "# Bank name column appended to the beginning of the dataframe\n",
    "separateBanksAndBranches <- function(stringData, origBank) {\n",
    "    stringData <- cbind(\"Bank\" = c(rep(NA, length(stringData$Col1))), stringData)\n",
    "    curIndex <- 1\n",
    "    for (i in stringData$Col1) {\n",
    "        if (grepl(\"BANK\", i) == TRUE | (grepl(\"MAIN OFFICE\", i) == FALSE & grepl(\"BRANCH\",i) == FALSE & grepl(\"FACILITY\", i) == FALSE)) {\n",
    "            stringData$Bank[curIndex] <- i    # copies bank name into new column\n",
    "        }\n",
    "        curIndex <- curIndex + 1\n",
    "    }\n",
    "    #assign the value of the bank name to each branch\n",
    "#    curIndex <- 1\n",
    "#    curBank <- origBank\n",
    "#    for (i in stringData$Bank) {\n",
    "#        if (is.na(i) == FALSE) {\n",
    "#            curBank <- i\n",
    "#        } else {\n",
    "#            stringData$Bank[curIndex] <- curBank\n",
    "#        }\n",
    "#        curIndex <- curIndex + 1\n",
    "#    }\n",
    "    \n",
    "    #remove bank names and only keep branch names in original first column\n",
    "#    deleteRows <- c(rep(TRUE, length(stringData$Bank)))\n",
    "#    count <- 1\n",
    "#    for (i in 1:length(stringData$Bank)) {\n",
    "#        if (grepl(\"MAIN OFFICE\", stringData$Col1[i]) == FALSE & grepl(\"BRANCH\", stringData$Col1[i]) == FALSE) {\n",
    "#            deleteRows[i] <- FALSE\n",
    "#        }\n",
    "#    }\n",
    "#    stringData <- stringData[deleteRows,]\n",
    "    colnames(stringData)[2] <- \"Branch\"\n",
    "    return(stringData)\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "cropColumns <- function(image, pageNum) {\n",
    "\n",
    "    # stores percentage that each column should take up\n",
    "    #col_pct <- c(0.36643, 0.15765, 0.09054, 0.12356, 0.09906, 0.04261)\n",
    "    # original:\n",
    "    #col_pct <- c(0.3863, 0.1608, 0.0906, 0.1202, 0.1127, 0.1158)\n",
    "    # adjusted for SciServer\n",
    "    col_pct <- c(0.418, 0.1608, 0.0906, 0.1202, 0.1127, 0.1158)\n",
    "    \n",
    "    # INITIAL BORDER CROP using cropPage function\n",
    "    cropPageReturns <- cropPage(image, pageNum)\n",
    "    if (is.null(cropPageReturns[[1]]) & is.null(cropPageReturns[[2]])) {\n",
    "        return(cropPageReturns) # return null list to indicate that cropping failed\n",
    "    }\n",
    "    cropped <- cropPageReturns[[1]] # magick image of full cropped page\n",
    "    returnList <- list(cropPageReturns[[2]]) # state for all data on this page\n",
    "    # -------------------------------------------------------------------------\n",
    "    # COMMENT 22-27, UNCOMMENT AND EDIT 31-32 FOR CROPPED SINGLE-PAGE READS\n",
    "    # -----------------------------------------------------------------------\n",
    "    # cropped <- image_read_pdf(\"1993B1_45.pdf\", density = 600)     # put cropped filename here\n",
    "    # returnList <- list(\"MASSACHUSETTS\")                             # put state for that page here\n",
    "    # CROP BY COUNTY SUMMARY TABLES \n",
    "    imgList <- findAndCrop(cropped, \"COUNTY TOTALS\")\n",
    "    if (length(imgList) == 1 & is.null(imgList[[1]])) {\n",
    "        print(\"no county summary tables on current page!\")\n",
    "        imgList <- list(cropped)\n",
    "    } else {\n",
    "        print(paste0(\"removed county summary tables, data from \", length(imgList), \" counties remain\"))\n",
    "    }\n",
    "    # CROP COLUMNS FOR EACH IMAGE\n",
    "    for (i in 1:length(imgList)) {\n",
    "        #image_write(imgList[[i]], path = paste0(pdfName, \"/table\", i, \".pdf\"), format = \"pdf\")\n",
    "        columns <- vector(\"character\", 6) # will hold OCR-extracted text for each column\n",
    "        width <- as.numeric(image_info(imgList[[i]])[2]) # set width and height for cropped page\n",
    "        height <- as.numeric(image_info(imgList[[i]])[3])\n",
    "        col_widths <- c(0, 0, 0, 0, 0, 0) # numeric vector to store pixel widths for each column\n",
    "        for (j in 1:length(col_pct)) {\n",
    "            col_widths[j] <- col_pct[j] * width\n",
    "            # print(col_widths)\n",
    "            if (j == length(col_pct)) {\n",
    "                geo <- paste0(width - sum(col_widths[1:j-1]), 'x', height, '+', sum(col_widths[1:j-1]), '+', 0)\n",
    "            } else {\n",
    "                geo <- paste0(col_widths[j], 'x', height, '+', sum(col_widths[1:j-1]), '+', 0)\n",
    "            }\n",
    "            #geo <- paste0(col_widths[j], 'x', height, '+', sum(col_widths[1:j-1]), '+', 0)\n",
    "            column <- image_crop(imgList[[i]], geo)\n",
    "            #image_write(column, path = paste0(pageNum, \"col\", j, \".pdf\"), format = \"pdf\")\n",
    "            columns[j] <- ocr(column, engine = tesseract(\"eng\"))\n",
    "        }\n",
    "        returnList <- c(returnList, list(columns))\n",
    "    }\n",
    "    return(returnList)\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#   Function to crop the data table out of the given page\n",
    "#   Parameters:\n",
    "#       img - the magick image file (the return value of image_read_pdf)\n",
    "#       page - the page number as a string\n",
    "#   Returns\n",
    "#       a list\n",
    "#           1st element is the magick image file of the cropped page\n",
    "#           2nd element is the state (as a string)\n",
    "#\n",
    "cropPage <- function(img, page) {\n",
    "    width <- as.numeric(image_info(img)[2])\n",
    "    height <- as.numeric(image_info(img)[3])                 \n",
    "    crop_geo <- paste0(width*.94, 'x', height*0.93, '+', width*.06, '+', 0)\n",
    "    croppedWatermark <- image_crop(img, crop_geo)\n",
    "    startX <- 0\n",
    "    while (startX <= image_info(croppedWatermark)[2]) {  # while startX less than width  \n",
    "        strip_geo <- paste0(60, 'x', image_info(croppedWatermark)[3], '+', startX, '+', 0) # vertical strip of width 60 from startX\n",
    "        strip <- image_crop(croppedWatermark, strip_geo)\n",
    "        text <- ocr(strip, engine = tesseract(\"eng\"))\n",
    "        if (text != '') {\n",
    "            break\n",
    "        }\n",
    "        startX <- startX + 30\n",
    "    }\n",
    "    startY <- 300\n",
    "    while (startY <= image_info(croppedWatermark)[3]) {  # while startY less than height  \n",
    "        strip_geo <- paste0(image_info(croppedWatermark)[2], 'x', 300, '+', 0, '+', startY - 300) # horizontal strip of height 300 from startY-300\n",
    "        strip <- image_crop(croppedWatermark, strip_geo)\n",
    "        text <- ocr(strip, engine = tesseract(\"eng\"))\n",
    "        if (grepl(\"DEPOSITS DEPOSITS\", text, fixed = TRUE) == TRUE) {   # end of column headers, only look for 2 to minimize tesseract errors\n",
    "            break\n",
    "        }\n",
    "        startY <- startY + 50\n",
    "    }\n",
    "    startY <- startY + 20\n",
    "    cutFromRight <- 20\n",
    "        while (cutFromRight <= image_info(croppedWatermark)[2] - startX) { # while cutFromRight less than new width \n",
    "        strip_geo <- paste0(160, 'x', image_info(croppedWatermark)[3], '+', image_info(croppedWatermark)[2] - cutFromRight - 160, '+', 0) # horizontal strip of height 100 from end-cutFromBottom\n",
    "        strip <- image_crop(croppedWatermark, strip_geo)\n",
    "        #image_write(strip, path = paste0(\"strip\", cutFromRight, \".pdf\"), format = \"pdf\")\n",
    "        text <- ocr(strip, engine = tesseract(\"eng\"))\n",
    "        if (grepl(\"TED\", text, fixed = TRUE) | grepl(\"ITS\", text, fixed = TRUE) | grepl(\"SIT\", text, fixed = TRUE)) {  \n",
    "            break\n",
    "        }\n",
    "        cutFromRight <- cutFromRight + 60\n",
    "    }\n",
    "    if (cutFromRight - 60 > 0) {\n",
    "        cutFromRight <- cutFromRight - 60\n",
    "    }\n",
    "    state <- \"statePlaceholder\"\n",
    "    cutFromBottom <- 100\n",
    "    while (cutFromBottom <= image_info(croppedWatermark)[3] - startY) {  # while cutFromBottom less than new height  \n",
    "        strip_geo <- paste0(image_info(croppedWatermark)[2], 'x', 100, '+', 0, '+', image_info(croppedWatermark)[3] - cutFromBottom) # horizontal strip of height 100 from end-cutFromBottom\n",
    "        strip <- image_crop(croppedWatermark, strip_geo)\n",
    "        text <- ocr(strip, engine = tesseract(\"eng\"))\n",
    "        if (grepl(page, text, fixed = TRUE) == TRUE) { # found page number\n",
    "            text <- strsplit(text, \"\\n\")[[1]][1] \n",
    "            words <- strsplit(text, \" \")[[1]]\n",
    "            if (length(words) == 2) {\n",
    "                state <- words[2]\n",
    "            } else {\n",
    "                state <- paste0(words[2], words[3])\n",
    "            }\n",
    "            # print(paste0(\"State: \", state))\n",
    "            break\n",
    "        }\n",
    "        cutFromBottom <- cutFromBottom + 40\n",
    "        if (cutFromBottom > 800) {\n",
    "            print(\"WARNING: page number not detected, cropping failed\")\n",
    "            return(list(NULL, NULL)) # return null list to indicate that cropping failed\n",
    "        }\n",
    "    }\n",
    "    crop_geo <- paste0(image_info(croppedWatermark)[2] - startX - cutFromRight, 'x', image_info(croppedWatermark)[3] - startY - cutFromBottom, '+', startX, '+', startY)\n",
    "    finalCropped <- image_crop(croppedWatermark, crop_geo)\n",
    "    print(paste0(\"cropped page dimensions: \", image_info(finalCropped)[2], \"w x \", image_info(finalCropped)[3], \"h\"))\n",
    "    if (image_info(finalCropped)[3] < 3000) {\n",
    "        print(\"WARNING: cropped table unusually small, check for data loss\")\n",
    "    }\n",
    "    returns <- list(finalCropped, state)\n",
    "    return(returns)\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "SUMMARY_TABLE_HEIGHT <- 450 # height of county summary table, in pixels\n",
    "\n",
    "findAndCrop <- function(img, phrase) {\n",
    "    fullText <- ocr(img, engine = tesseract(\"eng\"))\n",
    "    fullText <- strsplit(fullText, \"\\n\")[[1]]\n",
    "    countyTables <- grep(phrase, fullText)\n",
    "    numTables <- length(countyTables)\n",
    "    if (numTables == 0) {\n",
    "        return(list(NULL))\n",
    "    }\n",
    "    width <- as.numeric(image_info(img)[2])\n",
    "    height <- as.numeric(image_info(img)[3])\n",
    "    # print(paste0(\"width: \", width, \"  height: \", height))\n",
    "    # split whole image into top and bottom halves\n",
    "    geo <- paste0(width, 'x', height/2, '+', 0, '+', 0)\n",
    "    topHalf <- image_crop(img, geo)\n",
    "    geo <- paste0(width, 'x', height/2, '+', 0, '+', height/2)\n",
    "    botHalf <- image_crop(img, geo)\n",
    "    topText <- ocr(topHalf, engine = tesseract(\"eng\"))\n",
    "    topText <- strsplit(topText, \"\\n\")[[1]]\n",
    "    botText <- ocr(img, engine = tesseract(\"eng\"))\n",
    "    botText <- strsplit(botText, \"\\n\")[[1]]\n",
    "    numTablesTop <- length(grep(phrase, topText))\n",
    "    numTablesBot <- length(grep(phrase, botText))\n",
    "    imgToSearch <- NULL\n",
    "    botHalfIndicator <- FALSE\n",
    "    if (numTablesTop + numTablesBot != numTables) { # maybe \"COUNTY TOTALS\" was on the halfway line, \n",
    "        #                                           search whole page? would be inefficient but a rare case\n",
    "        imgToSearch <- img\n",
    "    } else if (numTablesTop == 0) { # case that all tables are in bottom half\n",
    "        imgToSearch <- botHalf\n",
    "        height <- height/2\n",
    "        botHalfIndicator <- TRUE\n",
    "        print(\"searching bottom half for county summary table\")\n",
    "    } else if (numTablesBot == 0) { # case that all tables are in top half\n",
    "        imgToSearch <- topHalf\n",
    "        height <- height/2\n",
    "        print(\"searching top half for county summary table\")\n",
    "    } else { # case that there are tables in both top and bottom halves, will search whole image\n",
    "        imgToSearch <- img\n",
    "    }\n",
    "    yCursor <- 0 # will iterate down imgToSearch to find county tables\n",
    "    tableLocations <- vector(mode = \"numeric\", length = numTables)\n",
    "    for (i in 1:numTables) {\n",
    "        # identify location of county table\n",
    "        while (yCursor < height) {\n",
    "            strip_geo <- paste0(width, 'x', 60, '+', 0, '+', yCursor) # crop geometry (type '?image_crop' for details)\n",
    "            strip <- image_crop(imgToSearch, strip_geo)\n",
    "            text <- ocr(strip, engine = tesseract(\"eng\"))\n",
    "            if (grepl(phrase, text, fixed = TRUE) == TRUE) {\n",
    "                break\n",
    "            }\n",
    "            yCursor <- yCursor + 20\n",
    "        } # now assuming yCursor points to the top of \"COUNTY TOTALS\"\n",
    "        tableLocations[i] <- yCursor\n",
    "        if (botHalfIndicator == TRUE) {\n",
    "            tableLocations[i] <- tableLocations[i] + height\n",
    "        }\n",
    "        yCursor <- yCursor + SUMMARY_TABLE_HEIGHT \n",
    "    }\n",
    "    # print(\"table locations: \")\n",
    "    # print(tableLocations)\n",
    "    imgList <- vector(mode = \"list\", length = numTables) # return list of images, will append last image if not blank\n",
    "    top <- 0  # will track y-coord where current image should start\n",
    "    for (i in 1:numTables) {\n",
    "        yDim <- tableLocations[[i]]\n",
    "        geo <- paste0(width, 'x', yDim - top, '+', 0, '+', top) # crop geometry (type '?image_crop' for details)\n",
    "        cropped <- image_crop(img, geo)\n",
    "        if (!(i == 1 & ocr(cropped, engine = tesseract(\"eng\")) == \"\")) { # check that section above first county table isn't blank\n",
    "            imgList[[i]] <- cropped \n",
    "        }\n",
    "        top <- yDim + SUMMARY_TABLE_HEIGHT\n",
    "    } # check that section after final county table isn't blank\n",
    "    geo <- paste0(width, 'x', as.numeric(image_info(img)[3]) - top, '+', 0, '+', top) # crop geometry (type '?image_crop' for details)\n",
    "    cropped <- image_crop(img, geo)    \n",
    "    text <- ocr(cropped, engine = tesseract(\"eng\"))\n",
    "    if (text != \"\") {\n",
    "        imgList <- c(imgList, cropped)\n",
    "    }\n",
    "    if (is.null(imgList[[1]])) {\n",
    "        return(imgList[-1]) # case that county table was at top of page, first image was blank\n",
    "    }\n",
    "    #image_write(imgList[[i]], path =\"findAndCrop/test.pdf\", format = \"pdf\")\n",
    "    return(imgList)\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# main(\"pathToPDF\", firstPageNum, \"firstCountyName\")\n",
    "main(\"/home/idies/workspace/Storage/Casey/persistent/1993B5_201-end.pdf\", 201, \"McDonald\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
